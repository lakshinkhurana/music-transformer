{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMa96xihRMeRFOv2onflyVV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":164,"metadata":{"id":"PE_qLyy-X0lQ","executionInfo":{"status":"ok","timestamp":1755987652961,"user_tz":-330,"elapsed":8,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pickle\n","import math\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["!git clone https://github.com/czhuang/JSB-Chorales-dataset.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yd6qM3nfX2XU","executionInfo":{"status":"ok","timestamp":1755987653084,"user_tz":-330,"elapsed":110,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"c1347b2a-07a7-4586-f471-995b59dfde44"},"execution_count":165,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'JSB-Chorales-dataset' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["with open('JSB-Chorales-dataset/jsb-chorales-16th.pkl', 'rb') as p:\n","    data = pickle.load(p, encoding=\"latin1\")"],"metadata":{"id":"ifDaMR_tX4RQ","executionInfo":{"status":"ok","timestamp":1755987653195,"user_tz":-330,"elapsed":76,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":166,"outputs":[]},{"cell_type":"code","source":["n_embd = 128\n","n_head = 8\n","head_size = n_embd // n_head\n","block_size=8\n","dropout=0.2\n"],"metadata":{"id":"fJuugGI5_dnG","executionInfo":{"status":"ok","timestamp":1755987653215,"user_tz":-330,"elapsed":10,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":167,"outputs":[]},{"cell_type":"code","source":["data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Glvm2JkX5t2","executionInfo":{"status":"ok","timestamp":1755987653222,"user_tz":-330,"elapsed":6,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"d1102311-66c4-4446-e2df-de3302216e02"},"execution_count":168,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['test', 'train', 'valid'])"]},"metadata":{},"execution_count":168}]},{"cell_type":"code","source":["print(np.array(data['train'],dtype=\"object\").shape)\n","print(np.array(data['test'],dtype=\"object\").shape)\n","print(np.array(data['valid'],dtype=\"object\").shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAvMhh7HX90U","executionInfo":{"status":"ok","timestamp":1755987653271,"user_tz":-330,"elapsed":37,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"e32396b1-b675-4275-b85c-c611ab627e0e"},"execution_count":169,"outputs":[{"output_type":"stream","name":"stdout","text":["(229,)\n","(77,)\n","(76,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49daee10","executionInfo":{"status":"ok","timestamp":1755987653272,"user_tz":-330,"elapsed":12,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"1d15204c-4658-44b9-aa08-bba6e838da04"},"source":["train_data = data['train']\n","print(f\"Type of train_data: {type(train_data)}\")\n","print(f\"Number of sequences in train_data: {len(train_data)}\")\n","print(f\"Type of the first sequence: {type(train_data[0])}\")\n","print(f\"Length of the first sequence: {len(train_data[0])}\")\n","print(f\"Type of the first element in the first sequence: {type(train_data[0][0])}\")\n","print(f\"Content of the first element in the first sequence:\\n{train_data[0][0]}\")"],"execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":["Type of train_data: <class 'list'>\n","Number of sequences in train_data: 229\n","Type of the first sequence: <class 'list'>\n","Length of the first sequence: 192\n","Type of the first element in the first sequence: <class 'tuple'>\n","Content of the first element in the first sequence:\n","(np.int64(74), np.int64(70), np.int64(65), np.int64(58))\n"]}]},{"cell_type":"code","source":["class Head(nn.Module):\n","  def __init__(self, head_size):\n","    super().__init__()\n","    self.key = nn.Linear(n_embd, head_size, bias=False)\n","    self.query = nn.Linear(n_embd, head_size, bias=False)\n","    self.value = nn.Linear(n_embd, head_size, bias=False)\n","    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","    self.dropout = nn.Dropout(dropout)\n","\n","    # Learnable relative positional embeddings\n","    self.relative_bias = nn.Parameter(torch.randn(block_size, block_size))\n","\n","  def forward(self, x):\n","    B, T, C = x.shape\n","    k = self.key(x)   # (B, T, head_size)\n","    q = self.query(x) # (B, T, head_size)\n","    v = self.value(x) # (B, T, head_size)\n","\n","    # Compute attention scores (\"affinities\")\n","    # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n","    wei = q @ k.transpose(-2, -1) * C**-0.5\n","\n","    # Add relative positional bias\n","    wei = wei + self.relative_bias[:T, :T]\n","\n","    # Apply causal masking\n","    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","\n","    # Apply softmax and dropout\n","    wei = F.softmax(wei, dim=-1) # (B, T, T)\n","    wei = self.dropout(wei)\n","\n","    # Perform the weighted aggregation of the values\n","    out = wei @ v # (B, T, T) @ (B, T, head_size) -> (B, T, head_size)\n","    return out"],"metadata":{"id":"pe_fO2pp-0CP","executionInfo":{"status":"ok","timestamp":1755987653273,"user_tz":-330,"elapsed":7,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":171,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, num_heads=n_head, head_size=n_embd//n_head):\n","    super().__init__()\n","    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","    self.proj = nn.Linear(n_embd, n_embd)\n","    self.dropout = nn.Dropout(dropout) # Add dropout layer\n","\n","  def forward(self, x):\n","    out = torch.cat([h(x) for h in self.heads], dim=-1)\n","    out = self.proj(out)\n","    out = self.dropout(out)\n","    return out"],"metadata":{"id":"KrOdJkG5udVa","executionInfo":{"status":"ok","timestamp":1755987653274,"user_tz":-330,"elapsed":7,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":172,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, n_embd, n_head, dropout=0.1):\n","        super().__init__()\n","        self.attn = MultiHeadAttention(n_head, head_size)\n","        self.norm1 = nn.LayerNorm(n_embd)\n","        self.norm2 = nn.LayerNorm(n_embd)\n","\n","        self.ffwd = nn.Sequential(\n","            nn.Linear(n_embd, n_embd * 4),  # expand (feed-forward inner layer)\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(n_embd * 4, n_embd),  # project back\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, input_tensor): # Renamed input variable\n","        # Pre-LN Attention\n","        print(f\"Shape before norm1 in TransformerBlock: {input_tensor.shape}\") # Use input_tensor\n","        x = input_tensor + self.attn(self.norm1(input_tensor)) # Use input_tensor for norm1\n","        print(f\"Shape after attention in TransformerBlock: {x.shape}\") # Add print statement\n","\n","        # Pre-LN Feed Forward\n","        print(f\"Shape before norm2 in TransformerBlock: {x.shape}\") # x is the output of attention\n","        x = x + self.ffwd(self.norm2(x))\n","        print(f\"Shape after ffwd in TransformerBlock: {x.shape}\") # Add print statement\n","\n","        return x"],"metadata":{"id":"RREIMFksv1v3","executionInfo":{"status":"ok","timestamp":1755987653275,"user_tz":-330,"elapsed":7,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":173,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    vocab_size=82\n","    self.embedding = nn.Embedding(vocab_size, n_embd)# Embedding layer to convert input tokens/events to embeddings\n","    self.transformer_blocks = nn.ModuleList([TransformerBlock(n_embd, n_head) for _ in range(8)])\n","\n","    # Output linear layer to predict the probability distribution over the event vocabulary\n","    self.linear = nn.Linear(n_embd, vocab_size)\n","\n","  def forward(self, x):\n","    x_embedded = self.embedding(x)\n","\n","    # Iterate through transformer blocks\n","    for i, block in enumerate(self.transformer_blocks):\n","        x_embedded = block(x_embedded)\n","    logits = self.linear(x_embedded)\n","    return logits # Return logits for CrossEntropyLoss"],"metadata":{"id":"1XOIUf_0xwQh","executionInfo":{"status":"ok","timestamp":1755987707274,"user_tz":-330,"elapsed":7,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":179,"outputs":[]},{"cell_type":"code","source":["model=Model()"],"metadata":{"id":"jFkpp5Kv6LS2","executionInfo":{"status":"ok","timestamp":1755987707851,"user_tz":-330,"elapsed":33,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":180,"outputs":[]},{"cell_type":"code","metadata":{"id":"abb91276","executionInfo":{"status":"ok","timestamp":1755987708043,"user_tz":-330,"elapsed":3,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"source":["# Define the optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Using Adam optimizer with a learning rate of 0.001\n","\n","# Define the loss function\n","criterion = nn.CrossEntropyLoss() # Using Cross-Entropy Loss, suitable for classification tasks like this"],"execution_count":181,"outputs":[]}]}