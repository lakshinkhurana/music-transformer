{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNf5NUb9vqHmTsgCLNTtfxI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"PE_qLyy-X0lQ","executionInfo":{"status":"ok","timestamp":1755898821184,"user_tz":-330,"elapsed":5199,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pickle\n","import math\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["!git clone https://github.com/czhuang/JSB-Chorales-dataset.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yd6qM3nfX2XU","executionInfo":{"status":"ok","timestamp":1755898822172,"user_tz":-330,"elapsed":998,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"1abfbdcd-bc6d-475b-873a-2d88b8df0f29"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'JSB-Chorales-dataset'...\n","remote: Enumerating objects: 46, done.\u001b[K\n","remote: Counting objects: 100% (10/10), done.\u001b[K\n","remote: Compressing objects: 100% (6/6), done.\u001b[K\n","remote: Total 46 (delta 4), reused 10 (delta 4), pack-reused 36 (from 1)\u001b[K\n","Receiving objects: 100% (46/46), 2.78 MiB | 13.24 MiB/s, done.\n","Resolving deltas: 100% (12/12), done.\n"]}]},{"cell_type":"code","source":["with open('JSB-Chorales-dataset/jsb-chorales-16th.pkl', 'rb') as p:\n","    data = pickle.load(p, encoding=\"latin1\")"],"metadata":{"id":"ifDaMR_tX4RQ","executionInfo":{"status":"ok","timestamp":1755898822428,"user_tz":-330,"elapsed":255,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["n_embd = 128\n","n_head = 8\n","head_size = n_embd // n_head\n","block_size=8\n","dropout=0.2\n"],"metadata":{"id":"fJuugGI5_dnG","executionInfo":{"status":"ok","timestamp":1755899267604,"user_tz":-330,"elapsed":7,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Glvm2JkX5t2","executionInfo":{"status":"ok","timestamp":1755898822523,"user_tz":-330,"elapsed":79,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"69b61b39-6493-46c3-9cb5-cc191db535d1"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['test', 'train', 'valid'])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["print(np.array(data['train'],dtype=\"object\").shape)\n","print(np.array(data['test'],dtype=\"object\").shape)\n","print(np.array(data['valid'],dtype=\"object\").shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAvMhh7HX90U","executionInfo":{"status":"ok","timestamp":1755898822528,"user_tz":-330,"elapsed":4,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"ebe144f9-5523-4f65-d445-c79ba94fbea1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["(229,)\n","(77,)\n","(76,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49daee10","executionInfo":{"status":"ok","timestamp":1755898822535,"user_tz":-330,"elapsed":4,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"66bdb372-ccc1-47d9-9bd5-2043e2411fa2"},"source":["train_data = data['train']\n","print(f\"Type of train_data: {type(train_data)}\")\n","print(f\"Number of sequences in train_data: {len(train_data)}\")\n","print(f\"Type of the first sequence: {type(train_data[0])}\")\n","print(f\"Length of the first sequence: {len(train_data[0])}\")\n","print(f\"Type of the first element in the first sequence: {type(train_data[0][0])}\")\n","print(f\"Content of the first element in the first sequence:\\n{train_data[0][0]}\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Type of train_data: <class 'list'>\n","Number of sequences in train_data: 229\n","Type of the first sequence: <class 'list'>\n","Length of the first sequence: 192\n","Type of the first element in the first sequence: <class 'tuple'>\n","Content of the first element in the first sequence:\n","(np.int64(74), np.int64(70), np.int64(65), np.int64(58))\n"]}]},{"cell_type":"code","source":["class Head(nn.Module):\n","  def __init__(self, head_size):\n","    super().__init__()\n","    self.key = nn.Linear(n_embd, head_size, bias=False)\n","    self.query = nn.Linear(n_embd, head_size, bias=False)\n","    self.value = nn.Linear(n_embd, head_size, bias=False)\n","    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","    self.dropout = nn.Dropout(dropout)\n","\n","    # Learnable relative positional embeddings\n","    self.relative_bias = nn.Parameter(torch.randn(block_size, block_size))\n","\n","  def forward(self, x):\n","    B, T, C = x.shape\n","    k = self.key(x)   # (B, T, head_size)\n","    q = self.query(x) # (B, T, head_size)\n","    v = self.value(x) # (B, T, head_size)\n","\n","    # Compute attention scores (\"affinities\")\n","    # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n","    wei = q @ k.transpose(-2, -1) * C**-0.5\n","\n","    # Add relative positional bias\n","    wei = wei + self.relative_bias[:T, :T]\n","\n","    # Apply causal masking\n","    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","\n","    # Apply softmax and dropout\n","    wei = F.softmax(wei, dim=-1) # (B, T, T)\n","    wei = self.dropout(wei)\n","\n","    # Perform the weighted aggregation of the values\n","    out = wei @ v # (B, T, T) @ (B, T, head_size) -> (B, T, head_size)\n","    return out"],"metadata":{"id":"pe_fO2pp-0CP","executionInfo":{"status":"ok","timestamp":1755898822579,"user_tz":-330,"elapsed":29,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, num_heads=n_head, head_size=n_embd//n_head):\n","    super().__init__()\n","    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","    self.proj = nn.Linear(n_embd, n_embd)\n","    self.dropout = nn.Dropout(dropout) # Add dropout layer\n","\n","  def forward(self, x):\n","    out = torch.cat([h(x) for h in self.heads], dim=-1)\n","    out = self.proj(out)\n","    out = self.dropout(out)\n","    return out"],"metadata":{"id":"KrOdJkG5udVa","executionInfo":{"status":"ok","timestamp":1755899190642,"user_tz":-330,"elapsed":42,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, n_embd, n_head, dropout=0.1):\n","        super().__init__()\n","        self.attn = MultiHeadAttention(n_head, head_size)\n","        self.norm1 = nn.LayerNorm(n_embd)\n","        self.norm2 = nn.LayerNorm(n_embd)\n","\n","        self.ffwd = nn.Sequential(\n","            nn.Linear(n_embd, n_embd * 4),  # expand (feed-forward inner layer)\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(n_embd * 4, n_embd),  # project back\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        # Pre-LN Attention\n","        x = x + self.attn(self.norm1(x))\n","\n","        # Pre-LN Feed Forward\n","        x = x + self.ffwd(self.norm2(x))\n","\n","        return x\n"],"metadata":{"id":"RREIMFksv1v3","executionInfo":{"status":"ok","timestamp":1755899692406,"user_tz":-330,"elapsed":10,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1XOIUf_0xwQh"},"execution_count":null,"outputs":[]}]}