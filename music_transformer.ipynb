{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyMx54Q8vs1EOxBq3ZnMOIvm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"34372df645b6455299009f63d486098e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd48cc55370d4770b1672919c13bceb7","IPY_MODEL_00c59748141b47498ac21a4fc3b49121","IPY_MODEL_dcd12736d0684c5b84792963f009a050"],"layout":"IPY_MODEL_d8e4d7abf5fc48538435cd599a45e2aa"}},"fd48cc55370d4770b1672919c13bceb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5da1529ec2e54fa5a19fb3c4dbf74086","placeholder":"​","style":"IPY_MODEL_2390163bc81d45778419412f3358e6d5","value":"Training: 100%"}},"00c59748141b47498ac21a4fc3b49121":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_815844440a5a475aaf8f96daddd687d3","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc89302a0f8543b4910167ac78854d25","value":8}},"dcd12736d0684c5b84792963f009a050":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b35f7a870a145208ddbb673c8656493","placeholder":"​","style":"IPY_MODEL_474dff70267e42299b0ae79f488c8141","value":" 8/8 [06:33&lt;00:00, 43.02s/it]"}},"d8e4d7abf5fc48538435cd599a45e2aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5da1529ec2e54fa5a19fb3c4dbf74086":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2390163bc81d45778419412f3358e6d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"815844440a5a475aaf8f96daddd687d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc89302a0f8543b4910167ac78854d25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b35f7a870a145208ddbb673c8656493":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"474dff70267e42299b0ae79f488c8141":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"217f90268cc349ae88176c8830d9485b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a47f56506a8b468da6ae43e83851789b","IPY_MODEL_419d0221ba5e45cabe16e330a4e372ff","IPY_MODEL_f85db424b35c4280955d9cccbf3470eb"],"layout":"IPY_MODEL_a02a22a1d2fc46f4aba3edb0798075f5"}},"a47f56506a8b468da6ae43e83851789b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f9a89c6e4fa463185ebf20ba09de63f","placeholder":"​","style":"IPY_MODEL_19ce5a410e254f14afd3dc08862d9a23","value":"Training: 100%"}},"419d0221ba5e45cabe16e330a4e372ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efbce54b5e334ceca7f39bd8a901db89","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cc259fe347844bfbee597aebea076f4","value":8}},"f85db424b35c4280955d9cccbf3470eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecabfa8b72f340d39b499261fe7ea5b5","placeholder":"​","style":"IPY_MODEL_1fa62cfdf705423b8f1e1cca10d7df53","value":" 8/8 [06:47&lt;00:00, 44.85s/it]"}},"a02a22a1d2fc46f4aba3edb0798075f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f9a89c6e4fa463185ebf20ba09de63f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19ce5a410e254f14afd3dc08862d9a23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efbce54b5e334ceca7f39bd8a901db89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cc259fe347844bfbee597aebea076f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ecabfa8b72f340d39b499261fe7ea5b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1fa62cfdf705423b8f1e1cca10d7df53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7093e13e79cd4a309202f7942afd8cef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8388ef65f1464949860fa929b2106844","IPY_MODEL_e1ca340831144309908bbc9c2c4b8fa7","IPY_MODEL_1cc58a804957440f80eca32b1c7e06f9"],"layout":"IPY_MODEL_3eca7c3b80f04fe1a10f0fdbc194628d"}},"8388ef65f1464949860fa929b2106844":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9473d1bc6084ccb859178e638de7c63","placeholder":"​","style":"IPY_MODEL_d547ba0d084c4cb3abfec8d104e552b3","value":"Evaluating: 100%"}},"e1ca340831144309908bbc9c2c4b8fa7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_438d0ced09234aa7a1aeaa02df616639","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8af77c27fa194ca08059fcd4c354f8d8","value":3}},"1cc58a804957440f80eca32b1c7e06f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec097d214d644ebb9c63784f5b8fdc91","placeholder":"​","style":"IPY_MODEL_435edd20dd8848f78bdff3df57b71304","value":" 3/3 [00:19&lt;00:00,  6.01s/it]"}},"3eca7c3b80f04fe1a10f0fdbc194628d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9473d1bc6084ccb859178e638de7c63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d547ba0d084c4cb3abfec8d104e552b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"438d0ced09234aa7a1aeaa02df616639":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8af77c27fa194ca08059fcd4c354f8d8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec097d214d644ebb9c63784f5b8fdc91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"435edd20dd8848f78bdff3df57b71304":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fNvQBgTRVnL","executionInfo":{"status":"ok","timestamp":1756142865007,"user_tz":-330,"elapsed":5238,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"527b5244-36f0-42e5-dec1-d0672fc88af8"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cpu)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.7.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n","Downloading torchmetrics-1.8.1-py3-none-any.whl (982 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.1\n"]}]},{"cell_type":"code","execution_count":59,"metadata":{"id":"PE_qLyy-X0lQ","executionInfo":{"status":"ok","timestamp":1756142901874,"user_tz":-330,"elapsed":43,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pickle\n","import math\n","from tqdm.auto import tqdm\n","import torchmetrics\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["!git clone https://github.com/czhuang/JSB-Chorales-dataset.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yd6qM3nfX2XU","executionInfo":{"status":"ok","timestamp":1756141676726,"user_tz":-330,"elapsed":148,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"842fec74-e852-489b-9aa0-1f8ba407109d"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'JSB-Chorales-dataset' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["with open('JSB-Chorales-dataset/jsb-chorales-16th.pkl', 'rb') as p:\n","    data = pickle.load(p, encoding=\"latin1\")"],"metadata":{"id":"ifDaMR_tX4RQ","executionInfo":{"status":"ok","timestamp":1756141676802,"user_tz":-330,"elapsed":76,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["n_embd = 128\n","n_head = 8\n","head_size = n_embd // n_head\n","block_size=4\n","dropout=0.2\n"],"metadata":{"id":"fJuugGI5_dnG","executionInfo":{"status":"ok","timestamp":1756141676804,"user_tz":-330,"elapsed":1,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Glvm2JkX5t2","executionInfo":{"status":"ok","timestamp":1756141676820,"user_tz":-330,"elapsed":15,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"71306bdf-6e69-418e-c4c5-2031fe9a5e35"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['test', 'train', 'valid'])"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["print(np.array(data['train'],dtype=\"object\").shape)\n","print(np.array(data['test'],dtype=\"object\").shape)\n","print(np.array(data['valid'],dtype=\"object\").shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAvMhh7HX90U","executionInfo":{"status":"ok","timestamp":1756141676851,"user_tz":-330,"elapsed":28,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"50481f7d-6687-439c-f658-6aa9472641df"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["(229,)\n","(77,)\n","(76,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49daee10","executionInfo":{"status":"ok","timestamp":1756141676869,"user_tz":-330,"elapsed":17,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"0b6b1ac2-c72a-496d-d110-f0ace3271d0d"},"source":["train_data = data['train']\n","print(f\"Type of train_data: {type(train_data)}\")\n","print(f\"Number of sequences in train_data: {len(train_data)}\")\n","print(f\"Type of the first sequence: {type(train_data[0])}\")\n","print(f\"Length of the first sequence: {len(train_data[0])}\")\n","print(f\"Type of the first element in the first sequence: {type(train_data[0][0])}\")\n","print(f\"Content of the first element in the first sequence:\\n{train_data[0][0]}\")"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Type of train_data: <class 'list'>\n","Number of sequences in train_data: 229\n","Type of the first sequence: <class 'list'>\n","Length of the first sequence: 192\n","Type of the first element in the first sequence: <class 'tuple'>\n","Content of the first element in the first sequence:\n","(np.int64(74), np.int64(70), np.int64(65), np.int64(58))\n"]}]},{"cell_type":"code","source":["train_dataset=data['train']\n","val_dataset=data['valid']\n","test_dataset=data['test']\n","\n","train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True)\n","val_loader=DataLoader(val_dataset,batch_size=32)\n","test_loader=DataLoader(test_dataset,batch_size=32)"],"metadata":{"id":"vRAolKJh5yg2","executionInfo":{"status":"ok","timestamp":1756141676878,"user_tz":-330,"elapsed":8,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["class Head(nn.Module):\n","  def __init__(self, head_size):\n","    super().__init__()\n","    self.key = nn.Linear(n_embd, head_size, bias=False)\n","    self.query = nn.Linear(n_embd, head_size, bias=False)\n","    self.value = nn.Linear(n_embd, head_size, bias=False)\n","    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","    self.dropout = nn.Dropout(dropout)\n","\n","    # Learnable relative positional embeddings\n","    # The size should be enough to cover relative distances up to block_size\n","    # For relative bias, the maximum relative distance in a sequence of length T is T-1.\n","    # If we consider distances from -(T-1) to T-1, we need 2*T - 1 unique biases.\n","    # However, relative positional bias is typically based on the difference in indices (j-i).\n","    # For a sequence of length T, the relative positions j-i range from -(T-1) to T-1.\n","    # The number of unique relative positions is 2*T - 1.\n","    # A common approach for relative positional bias in self-attention is to have\n","    # biases for relative distances within a certain window size, often related to block_size.\n","    # Let's assume the relative bias is for distances up to block_size in both directions.\n","    # The relative distance between index i and j is j - i.\n","    # The range of j-i for i, j in [0, T-1] is -(T-1) to T-1.\n","    # We need biases for these relative distances.\n","    # A simpler form of relative bias is to have a bias tensor of shape (2*block_size - 1)\n","    # and map the relative distance (j-i) to an index in this tensor.\n","\n","    # Let's redefine relative_bias to be for relative distances up to block_size\n","    # The relative distances (j-i) for 0 <= i, j < block_size range from -(block_size-1) to (block_size-1).\n","    # The number of unique relative distances is 2*block_size - 1.\n","    self.relative_bias = nn.Parameter(torch.randn(2 * block_size - 1))\n","\n","\n","  def forward(self, x):\n","    B, T, C = x.shape\n","    k = self.key(x)   # (B, T, head_size)\n","    q = self.query(x) # (B, T, head_size)\n","    v = self.value(x) # (B, T, head_size)\n","\n","    # Compute attention scores (\"affinities\")\n","    # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n","    wei = q @ k.transpose(-2, -1) * C**-0.5\n","\n","    # Add relative positional bias\n","    # Calculate relative positions for the current sequence length T\n","    i = torch.arange(T).unsqueeze(1).to(x.device)\n","    j = torch.arange(T).unsqueeze(0).to(x.device)\n","    relative_positions = j - i # Shape (T, T)\n","\n","    # Map relative positions to indices in self.relative_bias\n","    # The relative positions range from -(T-1) to T-1.\n","    # We need to map these to indices from 0 to 2*block_size - 2.\n","    # We can clip the relative positions to the range [-(block_size-1), block_size-1]\n","    # and then shift them to be non-negative indices.\n","    relative_positions_clipped = torch.clamp(relative_positions, min=-(block_size - 1), max=(block_size - 1))\n","    relative_bias_indices = relative_positions_clipped + (block_size - 1) # Shift to be non-negative\n","\n","    # Lookup bias values using the indices\n","    # self.relative_bias has shape (2*block_size - 1)\n","    # relative_bias_indices has shape (T, T)\n","    # The lookup should result in a tensor of shape (T, T)\n","    relative_bias_to_add = self.relative_bias[relative_bias_indices] # Shape (T, T)\n","\n","    # Add the relative bias to the attention scores\n","    wei = wei + relative_bias_to_add.unsqueeze(0) # Unsqueeze to broadcast across batch dimension (B, T, T) + (1, T, T)\n","\n","\n","    # Apply causal masking\n","    # The tril buffer was defined with block_size, need to adjust for current T\n","    tril_T = torch.tril(torch.ones(T, T, dtype=torch.bool, device=x.device))\n","    wei = wei.masked_fill(tril_T == 0, float('-inf')) # (B, T, T)\n","\n","\n","    # Apply softmax and dropout\n","    wei = F.softmax(wei, dim=-1) # (B, T, T)\n","    wei = self.dropout(wei)\n","\n","    # Perform the weighted aggregation of the values\n","    out = wei @ v # (B, T, T) @ (B, T, head_size) -> (B, T, head_size)\n","    return out"],"metadata":{"id":"pe_fO2pp-0CP","executionInfo":{"status":"ok","timestamp":1756141676881,"user_tz":-330,"elapsed":1,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, num_heads=n_head, head_size=n_embd//n_head):\n","    super().__init__()\n","    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","    self.proj = nn.Linear(n_embd, n_embd)\n","    self.dropout = nn.Dropout(dropout) # Add dropout layer\n","\n","  def forward(self, x):\n","    out = torch.cat([h(x) for h in self.heads], dim=-1)\n","    out = self.proj(out)\n","    out = self.dropout(out)\n","    return out"],"metadata":{"id":"KrOdJkG5udVa","executionInfo":{"status":"ok","timestamp":1756141676882,"user_tz":-330,"elapsed":0,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","    def __init__(self, n_embd, n_head, dropout=0.1):\n","        super().__init__()\n","        self.attn = MultiHeadAttention(n_head, head_size)\n","        self.norm1 = nn.LayerNorm(n_embd)\n","        self.norm2 = nn.LayerNorm(n_embd)\n","\n","        self.ffwd = nn.Sequential(\n","            nn.Linear(n_embd, n_embd * 4),  # expand (feed-forward inner layer)\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(n_embd * 4, n_embd),  # project back\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, input_tensor): # Renamed input variable\n","        # Pre-LN Attention\n","        # print(f\"Shape before norm1 in TransformerBlock: {input_tensor.shape}\") # Use input_tensor\n","        x = input_tensor + self.attn(self.norm1(input_tensor)) # Use input_tensor for norm1\n","        # print(f\"Shape after attention in TransformerBlock: {x.shape}\") # Add print statement\n","\n","        # Pre-LN Feed Forward\n","        # print(f\"Shape before norm2 in TransformerBlock: {x.shape}\") # x is the output of attention\n","        x = x + self.ffwd(self.norm2(x))\n","        # print(f\"Shape after ffwd in TransformerBlock: {x.shape}\") # Add print statement\n","\n","        return x"],"metadata":{"id":"RREIMFksv1v3","executionInfo":{"status":"ok","timestamp":1756141676884,"user_tz":-330,"elapsed":1,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    vocab_size=82 # Assuming this is the total number of unique note/event values across all voices\n","    self.embedding = nn.Embedding(vocab_size, n_embd)# Embedding layer to convert input tokens/events to embeddings\n","    self.transformer_blocks = nn.ModuleList([TransformerBlock(n_embd, n_head) for _ in range(8)])\n","\n","    # Output linear layer to predict the probability distribution over the event vocabulary\n","    self.linear = nn.Linear(n_embd, vocab_size)\n","\n","  def forward(self, x):\n","    # x shape: (batch_size, sequence_length, 4)\n","    batch_size, seq_len, num_voices = x.shape\n","\n","    # Embed each of the 4 voice dimensions and sum the embeddings\n","    # This assumes the embeddings for each voice at a time step are additive.\n","    embeddings_sum = torch.zeros(batch_size, seq_len, n_embd, device=x.device)\n","    for i in range(num_voices):\n","        embeddings_sum += self.embedding(x[:, :, i])\n","\n","    x_processed = embeddings_sum\n","\n","    # Iterate through transformer blocks\n","    for i, block in enumerate(self.transformer_blocks):\n","        # The input to the transformer blocks is now (batch_size, sequence_length, n_embd)\n","        x_processed = block(x_processed)\n","\n","    # The output of the last transformer block is (batch_size, sequence_length, n_embd)\n","    # Apply the linear layer to the last dimension (n_embd)\n","    # This will give output of shape (batch_size, seq_len, vocab_size)\n","    logits = self.linear(x_processed)\n","\n","    return logits"],"metadata":{"id":"1XOIUf_0xwQh","executionInfo":{"status":"ok","timestamp":1756141676898,"user_tz":-330,"elapsed":13,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["model=Model()"],"metadata":{"id":"jFkpp5Kv6LS2","executionInfo":{"status":"ok","timestamp":1756141677248,"user_tz":-330,"elapsed":349,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"abb91276","executionInfo":{"status":"ok","timestamp":1756141677406,"user_tz":-330,"elapsed":102,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"source":["# Define the optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # Using Adam optimizer with a learning rate of 0.001\n","\n","# Define the loss function\n","criterion = nn.CrossEntropyLoss() # Using Cross-Entropy Loss, suitable for classification tasks like this"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03127d70","executionInfo":{"status":"ok","timestamp":1756141677424,"user_tz":-330,"elapsed":17,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"c670cd78-3507-44b3-fc59-98d3243a19d8"},"source":["def pad_collate(batch):\n","    # Find the maximum sequence length in the batch\n","    max_len = max(len(seq) for seq in batch)\n","    if max_len == 0:\n","        return torch.empty(0, 0, 4, dtype=torch.long)\n","\n","    batch_size = len(batch)\n","    # Create a tensor filled with padding values\n","    # Assuming padding value is 0\n","    padded_batch_tensor = torch.full((batch_size, max_len, 4), 0, dtype=torch.long)\n","\n","    # Fill the tensor with actual sequence data\n","    for i, seq in enumerate(batch):\n","        # Debug prints for each sequence and its items\n","        # print(f\"Processing Sequence {i}, Length: {len(seq)}\")\n","        seq_list_of_lists = []\n","        for item_idx, item in enumerate(seq):\n","            # print(f\"  Sequence {i}, Item {item_idx}: {item}, Type: {type(item)}\")\n","            try:\n","                item_list = list(item)\n","                # print(f\"  Sequence {i}, Item {item_idx}: Converted list: {item_list}, Length: {len(item_list)}\")\n","                seq_list_of_lists.append(item_list)\n","            except Exception as e:\n","                print(f\"  Sequence {i}, Item {item_idx}: Error converting item {item}: {e}\")\n","\n","\n","        # Convert the sequence list of lists to a tensor\n","        if len(seq_list_of_lists) > 0:\n","            try:\n","                seq_tensor = torch.tensor(seq_list_of_lists, dtype=torch.long)\n","                 # print(f\"  Sequence {i}: Created seq_tensor with shape {seq_tensor.shape}\")\n","                # Place the sequence tensor into the pre-allocated batch tensor\n","                padded_batch_tensor[i, :len(seq), :] = seq_tensor\n","            except ValueError as e:\n","                 print(f\"  Sequence {i}: ValueError when creating seq_tensor: {e}\")\n","                 # You might want to inspect seq_list_of_lists here if this error occurs\n","                 # print(f\"  Sequence {i}: seq_list_of_lists causing error: {seq_list_of_lists}\")\n","\n","\n","    return padded_batch_tensor\n","\n","# Re-initialize DataLoaders with the custom collate function\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=pad_collate)\n","val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=pad_collate)\n","test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=pad_collate)\n","\n","print(\"DataLoaders re-initialized with custom collate function to handle variable sequence lengths.\")"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["DataLoaders re-initialized with custom collate function to handle variable sequence lengths.\n"]}]},{"cell_type":"code","metadata":{"id":"dda0c40e","executionInfo":{"status":"ok","timestamp":1756141677432,"user_tz":-330,"elapsed":7,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"source":["from tqdm.auto import tqdm # Import tqdm\n","\n","def train(model, train_loader, optimizer, criterion):\n","    model.train()  # Set the model to training mode\n","    running_loss = 0.0\n","    # Wrap the train_loader with tqdm for a progress bar\n","    for i, inputs in enumerate(tqdm(train_loader, desc=\"Training\")):\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        # inputs shape: (batch_size, seq_len, 4)\n","        outputs = model(inputs) # outputs shape: (batch_size, seq_len, vocab_size)\n","\n","        # Prepare targets\n","        # Assuming target for time step t is the first value at time step t+1\n","        # We need to shift the inputs to get the targets\n","        # targets shape: (batch_size, seq_len) - we will exclude the last time step\n","        targets = inputs[:, 1:, 0] # Take all batches, from second time step onwards, first feature\n","        # outputs shape for loss: (batch_size * (seq_len - 1), vocab_size)\n","        # targets shape for loss: (batch_size * (seq_len - 1))\n","\n","        # Reshape outputs and targets for CrossEntropyLoss\n","        # CrossEntropyLoss expects inputs of shape (N, C) and targets of shape (N)\n","        batch_size, seq_len, vocab_size = outputs.shape\n","        # Exclude the last time step from outputs\n","        outputs_for_loss = outputs[:, :-1, :].contiguous().view(-1, vocab_size)\n","        # Flatten targets\n","        targets_for_loss = targets.contiguous().view(-1)\n","\n","\n","        loss = criterion(outputs_for_loss, targets_for_loss)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Print statistics\n","        running_loss += loss.item()\n","        # We can update the progress bar description with the current loss\n","        if i % 10 == 9:\n","             tqdm.write(f'[{i + 1}] loss: {running_loss / 10:.3f}') # Use tqdm.write to print without interfering with the progress bar\n","             running_loss = 0.0\n","\n","\n","    print('Finished Training')"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286,"referenced_widgets":["34372df645b6455299009f63d486098e","fd48cc55370d4770b1672919c13bceb7","00c59748141b47498ac21a4fc3b49121","dcd12736d0684c5b84792963f009a050","d8e4d7abf5fc48538435cd599a45e2aa","5da1529ec2e54fa5a19fb3c4dbf74086","2390163bc81d45778419412f3358e6d5","815844440a5a475aaf8f96daddd687d3","dc89302a0f8543b4910167ac78854d25","5b35f7a870a145208ddbb673c8656493","474dff70267e42299b0ae79f488c8141"]},"id":"34d29e52","executionInfo":{"status":"ok","timestamp":1756142070906,"user_tz":-330,"elapsed":393472,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"19028ed9-22c4-4c26-c965-189625a57a9d"},"source":["train(model, train_loader, optimizer, criterion)"],"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":["Training:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34372df645b6455299009f63d486098e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  Sequence 4: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 25: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 4: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 18: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 19: ValueError when creating seq_tensor: expected sequence of length 1 at dim 1 (got 4)\n","  Sequence 29: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 5: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 11: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 31: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 4: ValueError when creating seq_tensor: expected sequence of length 1 at dim 1 (got 4)\n","  Sequence 18: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 21: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","Finished Training\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["217f90268cc349ae88176c8830d9485b","a47f56506a8b468da6ae43e83851789b","419d0221ba5e45cabe16e330a4e372ff","f85db424b35c4280955d9cccbf3470eb","a02a22a1d2fc46f4aba3edb0798075f5","0f9a89c6e4fa463185ebf20ba09de63f","19ce5a410e254f14afd3dc08862d9a23","efbce54b5e334ceca7f39bd8a901db89","8cc259fe347844bfbee597aebea076f4","ecabfa8b72f340d39b499261fe7ea5b5","1fa62cfdf705423b8f1e1cca10d7df53"]},"id":"1edf99f4","executionInfo":{"status":"ok","timestamp":1756142478177,"user_tz":-330,"elapsed":407167,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"14588d2d-8233-4c1f-e024-82f55b37409e"},"source":["print(\"Continuing training...\")\n","train(model, train_loader, optimizer, criterion)"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Continuing training...\n"]},{"output_type":"display_data","data":{"text/plain":["Training:   0%|          | 0/8 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"217f90268cc349ae88176c8830d9485b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  Sequence 15: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 23: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 15: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 20: ValueError when creating seq_tensor: expected sequence of length 1 at dim 1 (got 4)\n","  Sequence 8: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 9: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 18: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 15: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 11: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 14: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 23: ValueError when creating seq_tensor: expected sequence of length 1 at dim 1 (got 4)\n","  Sequence 25: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","Finished Training\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1e0de87a","executionInfo":{"status":"ok","timestamp":1756142478271,"user_tz":-330,"elapsed":58,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"3ef9f4b9-c208-409b-a02b-d5f53b3b9918"},"source":["# Define the path to save the model\n","model_save_path = 'model.pth'\n","\n","# Save the model's state dictionary\n","torch.save(model.state_dict(), model_save_path)\n","\n","print(f\"Model saved successfully to {model_save_path}\")"],"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved successfully to model.pth\n"]}]},{"cell_type":"code","metadata":{"id":"06c8051c","executionInfo":{"status":"ok","timestamp":1756142916212,"user_tz":-330,"elapsed":3,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"source":["def evaluate(model, data_loader, criterion):\n","    model.eval()  # Set the model to evaluation mode\n","    total_loss = 0.0\n","    correct_predictions = 0\n","    total_predictions = 0\n","\n","    # Initialize accuracy metric\n","    accuracy_metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=82) # Assuming vocab_size is 82\n","\n","    with torch.no_grad(): # Disable gradient calculation\n","        # Wrap the data_loader with tqdm for a progress bar\n","        for inputs in tqdm(data_loader, desc=\"Evaluating\"):\n","            # Forward pass\n","            outputs = model(inputs)\n","\n","            # Prepare targets\n","            targets = inputs[:, 1:, 0] # Take all batches, from second time step onwards, first feature\n","\n","            # Reshape outputs and targets for CrossEntropyLoss\n","            batch_size, seq_len, vocab_size = outputs.shape\n","            outputs_for_loss = outputs[:, :-1, :].contiguous().view(-1, vocab_size)\n","            targets_for_loss = targets.contiguous().view(-1)\n","\n","            # Calculate loss\n","            loss = criterion(outputs_for_loss, targets_for_loss)\n","            total_loss += loss.item() * inputs.size(0) # Accumulate loss, weighted by batch size\n","\n","            # Calculate accuracy\n","            # Get the predicted token for each position\n","            predicted_tokens = torch.argmax(outputs_for_loss, dim=-1)\n","            # Update accuracy metric\n","            accuracy_metric.update(predicted_tokens.cpu(), targets_for_loss.cpu())\n","\n","\n","    average_loss = total_loss / len(data_loader.dataset) # Calculate average loss\n","    perplexity = torch.exp(torch.tensor(average_loss)) # Calculate perplexity\n","    accuracy = accuracy_metric.compute() # Compute final accuracy\n","\n","    print(f'Evaluation Loss: {average_loss:.3f}, Perplexity: {perplexity:.3f}, Accuracy: {accuracy:.3f}')\n","    return average_loss, perplexity, accuracy # Return all metrics\n","\n","# Evaluate on the validation set\n","# print(\"Evaluating on validation set...\")\n","# evaluate(model, val_loader, criterion)\n","\n","# Evaluate on the test set (optional, usually done after final model selection)\n","# print(\"Evaluating on test set...\")\n","# evaluate(model, test_loader, criterion)"],"execution_count":60,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nJNC-vw3LLK1","executionInfo":{"status":"ok","timestamp":1756142918782,"user_tz":-330,"elapsed":15,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286,"referenced_widgets":["7093e13e79cd4a309202f7942afd8cef","8388ef65f1464949860fa929b2106844","e1ca340831144309908bbc9c2c4b8fa7","1cc58a804957440f80eca32b1c7e06f9","3eca7c3b80f04fe1a10f0fdbc194628d","a9473d1bc6084ccb859178e638de7c63","d547ba0d084c4cb3abfec8d104e552b3","438d0ced09234aa7a1aeaa02df616639","8af77c27fa194ca08059fcd4c354f8d8","ec097d214d644ebb9c63784f5b8fdc91","435edd20dd8848f78bdff3df57b71304"]},"id":"00083487","executionInfo":{"status":"ok","timestamp":1756143001230,"user_tz":-330,"elapsed":20192,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"a7431909-24db-4ffd-ef78-3c96e74da577"},"source":["# Evaluate on the test set\n","print(\"Evaluating on test set...\")\n","test_loss = evaluate(model, test_loader, criterion)"],"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating on test set...\n"]},{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7093e13e79cd4a309202f7942afd8cef"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["  Sequence 6: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 18: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 20: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 23: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 0: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 3: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 16: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 21: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 6: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 3)\n","  Sequence 7: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","  Sequence 12: ValueError when creating seq_tensor: expected sequence of length 4 at dim 1 (got 0)\n","Evaluation Loss: 0.455, Perplexity: 1.577, Accuracy: 0.911\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"prOWpW43Rlw9"},"execution_count":null,"outputs":[]}]}