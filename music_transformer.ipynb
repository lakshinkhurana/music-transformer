{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOFvIYd7nXwX/9zdIzob0ei"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"PE_qLyy-X0lQ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import pickle\n","import math\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","source":["!git clone https://github.com/czhuang/JSB-Chorales-dataset.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yd6qM3nfX2XU","executionInfo":{"status":"ok","timestamp":1755610814813,"user_tz":-330,"elapsed":106,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"4138e8c9-b0bf-4484-ce91-3ec51925729f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'JSB-Chorales-dataset' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["with open('JSB-Chorales-dataset/jsb-chorales-16th.pkl', 'rb') as p:\n","    data = pickle.load(p, encoding=\"latin1\")"],"metadata":{"id":"ifDaMR_tX4RQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_embd = 128\n","n_head = 4"],"metadata":{"id":"fJuugGI5_dnG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Glvm2JkX5t2","executionInfo":{"status":"ok","timestamp":1755610816679,"user_tz":-330,"elapsed":10,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"68c4ed4b-3239-41ea-dade-984bc0302902"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['test', 'train', 'valid'])"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["print(np.array(data['train'],dtype=\"object\").shape)\n","print(np.array(data['test'],dtype=\"object\").shape)\n","print(np.array(data['valid'],dtype=\"object\").shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LAvMhh7HX90U","executionInfo":{"status":"ok","timestamp":1755610817269,"user_tz":-330,"elapsed":4,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"fab58dc3-abf6-4e67-efe9-37259b7ce86c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(229,)\n","(77,)\n","(76,)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49daee10","executionInfo":{"status":"ok","timestamp":1755610818069,"user_tz":-330,"elapsed":10,"user":{"displayName":"Lakshin Khurana","userId":"08630988451898274766"}},"outputId":"448e07e7-5e70-42fd-cc82-4129123aeae0"},"source":["train_data = data['train']\n","print(f\"Type of train_data: {type(train_data)}\")\n","print(f\"Number of sequences in train_data: {len(train_data)}\")\n","print(f\"Type of the first sequence: {type(train_data[0])}\")\n","print(f\"Length of the first sequence: {len(train_data[0])}\")\n","print(f\"Type of the first element in the first sequence: {type(train_data[0][0])}\")\n","print(f\"Content of the first element in the first sequence:\\n{train_data[0][0]}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Type of train_data: <class 'list'>\n","Number of sequences in train_data: 229\n","Type of the first sequence: <class 'list'>\n","Length of the first sequence: 192\n","Type of the first element in the first sequence: <class 'tuple'>\n","Content of the first element in the first sequence:\n","(np.int64(74), np.int64(70), np.int64(65), np.int64(58))\n"]}]},{"cell_type":"code","source":["class Head(nn.Module):\n","  def __init__(self, head_size):\n","    super().__init__()\n","    self.key = nn.Linear(n_embd, head_size, bias=False)\n","    self.query = nn.Linear(n_embd, head_size, bias=False)\n","    self.value = nn.Linear(n_embd, head_size, bias=False)\n","    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","    self.dropout = nn.Dropout(dropout)\n","\n","    # Learnable relative positional embeddings\n","    self.relative_bias = nn.Parameter(torch.randn(block_size, block_size))\n","\n","  def forward(self, x):\n","    B, T, C = x.shape\n","    k = self.key(x)   # (B, T, head_size)\n","    q = self.query(x) # (B, T, head_size)\n","    v = self.value(x) # (B, T, head_size)\n","\n","    # Compute attention scores (\"affinities\")\n","    # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n","    wei = q @ k.transpose(-2, -1) * C**-0.5\n","\n","    # Add relative positional bias\n","    wei = wei + self.relative_bias[:T, :T]\n","\n","    # Apply causal masking\n","    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","\n","    # Apply softmax and dropout\n","    wei = F.softmax(wei, dim=-1) # (B, T, T)\n","    wei = self.dropout(wei)\n","\n","    # Perform the weighted aggregation of the values\n","    out = wei @ v # (B, T, T) @ (B, T, head_size) -> (B, T, head_size)\n","    return out"],"metadata":{"id":"pe_fO2pp-0CP"},"execution_count":null,"outputs":[]}]}