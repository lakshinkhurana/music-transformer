{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5199,
     "status": "ok",
     "timestamp": 1755898821184,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "PE_qLyy-X0lQ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 998,
     "status": "ok",
     "timestamp": 1755898822172,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "Yd6qM3nfX2XU",
    "outputId": "1abfbdcd-bc6d-475b-873a-2d88b8df0f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'JSB-Chorales-dataset'...\n",
      "remote: Enumerating objects: 46, done.\u001b[K\n",
      "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
      "remote: Total 46 (delta 4), reused 10 (delta 4), pack-reused 36 (from 1)\u001b[K\n",
      "Receiving objects: 100% (46/46), 2.78 MiB | 13.24 MiB/s, done.\n",
      "Resolving deltas: 100% (12/12), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/czhuang/JSB-Chorales-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1755898822428,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "ifDaMR_tX4RQ"
   },
   "outputs": [],
   "source": [
    "with open('JSB-Chorales-dataset/jsb-chorales-16th.pkl', 'rb') as p:\n",
    "    data = pickle.load(p, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1755899267604,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "fJuugGI5_dnG"
   },
   "outputs": [],
   "source": [
    "n_embd = 128\n",
    "n_head = 8\n",
    "head_size = n_embd // n_head\n",
    "block_size=8\n",
    "dropout=0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79,
     "status": "ok",
     "timestamp": 1755898822523,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "5Glvm2JkX5t2",
    "outputId": "69b61b39-6493-46c3-9cb5-cc191db535d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'valid'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1755898822528,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "LAvMhh7HX90U",
    "outputId": "ebe144f9-5523-4f65-d445-c79ba94fbea1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229,)\n",
      "(77,)\n",
      "(76,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(data['train'],dtype=\"object\").shape)\n",
    "print(np.array(data['test'],dtype=\"object\").shape)\n",
    "print(np.array(data['valid'],dtype=\"object\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1755898822535,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "49daee10",
    "outputId": "66bdb372-ccc1-47d9-9bd5-2043e2411fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of train_data: <class 'list'>\n",
      "Number of sequences in train_data: 229\n",
      "Type of the first sequence: <class 'list'>\n",
      "Length of the first sequence: 192\n",
      "Type of the first element in the first sequence: <class 'tuple'>\n",
      "Content of the first element in the first sequence:\n",
      "(np.int64(74), np.int64(70), np.int64(65), np.int64(58))\n"
     ]
    }
   ],
   "source": [
    "train_data = data['train']\n",
    "print(f\"Type of train_data: {type(train_data)}\")\n",
    "print(f\"Number of sequences in train_data: {len(train_data)}\")\n",
    "print(f\"Type of the first sequence: {type(train_data[0])}\")\n",
    "print(f\"Length of the first sequence: {len(train_data[0])}\")\n",
    "print(f\"Type of the first element in the first sequence: {type(train_data[0][0])}\")\n",
    "print(f\"Content of the first element in the first sequence:\\n{train_data[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1755898822579,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "pe_fO2pp-0CP"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "  def __init__(self, head_size):\n",
    "    super().__init__()\n",
    "    self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Learnable relative positional embeddings\n",
    "    self.relative_bias = nn.Parameter(torch.randn(block_size, block_size))\n",
    "\n",
    "  def forward(self, x):\n",
    "    B, T, C = x.shape\n",
    "    k = self.key(x)   # (B, T, head_size)\n",
    "    q = self.query(x) # (B, T, head_size)\n",
    "    v = self.value(x) # (B, T, head_size)\n",
    "\n",
    "    # Compute attention scores (\"affinities\")\n",
    "    # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n",
    "    wei = q @ k.transpose(-2, -1) * C**-0.5\n",
    "\n",
    "    # Add relative positional bias\n",
    "    wei = wei + self.relative_bias[:T, :T]\n",
    "\n",
    "    # Apply causal masking\n",
    "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "\n",
    "    # Apply softmax and dropout\n",
    "    wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "    wei = self.dropout(wei)\n",
    "\n",
    "    # Perform the weighted aggregation of the values\n",
    "    out = wei @ v # (B, T, T) @ (B, T, head_size) -> (B, T, head_size)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1755899190642,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "KrOdJkG5udVa"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, num_heads=n_head, head_size=n_embd//n_head):\n",
    "    super().__init__()\n",
    "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "    self.proj = nn.Linear(n_embd, n_embd)\n",
    "    self.dropout = nn.Dropout(dropout) # Add dropout layer\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "    out = self.proj(out)\n",
    "    out = self.dropout(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1755899692406,
     "user": {
      "displayName": "Lakshin Khurana",
      "userId": "08630988451898274766"
     },
     "user_tz": -330
    },
    "id": "RREIMFksv1v3"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, n_embd, n_head, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadAttention(n_head, head_size)\n",
    "        self.norm1 = nn.LayerNorm(n_embd)\n",
    "        self.norm2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "        self.ffwd = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd * 4),  # expand (feed-forward inner layer)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_embd * 4, n_embd),  # project back\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pre-LN Attention\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "\n",
    "        # Pre-LN Feed Forward\n",
    "        x = x + self.ffwd(self.norm2(x))\n",
    "\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNf5NUb9vqHmTsgCLNTtfxI",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
